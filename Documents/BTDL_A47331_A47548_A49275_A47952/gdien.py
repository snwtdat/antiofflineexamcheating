import streamlit as st
import cv2
import numpy as np
from ultralytics import YOLO
from PIL import Image
import tempfile

# --- C·∫§U H√åNH TRANG WEB ---
st.set_page_config(page_title="H·ªá th·ªëng Ph√°t hi·ªán Gian l·∫≠n", layout="wide")
st.title("üö´ AI Detection: H·ªá th·ªëng Ph√°t hi·ªán Gian l·∫≠n")
st.sidebar.header("C·∫•u h√¨nh m√¥ h√¨nh")

# --- T·∫¢I M√î H√åNH ---
@st.cache_resource
def load_model():
    return YOLO('/Users/softann/Documents/BTDL_A47331_A47548_A49275_A47952/best.pt')  # ƒê·∫£m b·∫£o file best.pt n·∫±m c√πng th∆∞ m·ª•c

model = load_model()

# --- THANH C√îNG C·ª§ B√äN TR√ÅI ---
conf_threshold = st.sidebar.slider("Ng∆∞·ª°ng tin c·∫≠y (Confidence)", 0.0, 1.0, 0.5)
blocked_ids = st.sidebar.multiselect(
    "Ch·∫∑n c√°c Class ID (Kh√¥ng hi·ªÉn th·ªã):", 
    options=list(model.names.keys()), 
    format_func=lambda x: model.names[x]
)

source_type = st.sidebar.radio("Ch·ªçn lo·∫°i t·ªáp tin:", ("·∫¢nh", "Video"))
uploaded_file = st.sidebar.file_uploader(f"T·∫£i l√™n {source_type.lower()}", type=['jpg', 'jpeg', 'png', 'mp4', 'mov', 'avi'])

# --- X·ª¨ L√ù ·∫¢NH ---
if source_type == "·∫¢nh" and uploaded_file:
    image = Image.open(uploaded_file)
    if image.mode == 'RGBA':
        image = image.convert('RGB')
    img_array = np.array(image)
    
    # Predict
    results = model.predict(img_array, conf=conf_threshold)
    
    # V·∫Ω k·∫øt qu·∫£ (S·ª≠ d·ª•ng h√†m plot c·ªßa YOLO cho nhanh ho·∫∑c t√πy bi·∫øn nh∆∞ code c≈© c·ªßa b·∫°n)
    res_plotted = results[0].plot() # B·∫°n c√≥ th·ªÉ vi·∫øt l·∫°i h√†m v·∫Ω ri√™ng n·∫øu mu·ªën l·ªçc blocked_ids
    
    col1, col2 = st.columns(2)
    with col1:
        st.subheader("·∫¢nh g·ªëc")
        st.image(image, use_container_width=True)
    with col2:
        st.subheader("K·∫øt qu·∫£ ƒë√°nh gi√°")
        st.image(res_plotted, channels="BGR", use_container_width=True)

# --- X·ª¨ L√ù VIDEO ---
elif source_type == "Video" and uploaded_file:
    tfile = tempfile.NamedTemporaryFile(delete=False) 
    tfile.write(uploaded_file.read())
    cap = cv2.VideoCapture(tfile.name)
    
    st.subheader("Lu·ªìng x·ª≠ l√Ω Video")
    frame_window = st.image([]) # T·∫°o m·ªôt khung tr·ªëng ƒë·ªÉ c·∫≠p nh·∫≠t video

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
        
        # X·ª≠ l√Ω YOLO
        results = model.predict(frame, conf=conf_threshold, verbose=False)
        
        # V·∫Ω th·ªß c√¥ng ƒë·ªÉ √°p d·ª•ng blocked_ids (gi·ªëng code c·ªßa b·∫°n)
        for result in results:
            for box in result.boxes:
                cls_id = int(box.cls[0])
                if cls_id in blocked_ids:
                    continue
                
                x1, y1, x2, y2 = map(int, box.xyxy[0])
                label = model.names[cls_id]
                conf = float(box.conf[0])
                
                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 3) # M√†u ƒë·ªè cho gian l·∫≠n
                cv2.putText(frame, f"{label} {conf:.2f}", (x1, y1 - 10), 
                            cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)

        # Chuy·ªÉn m√†u t·ª´ BGR sang RGB ƒë·ªÉ hi·ªÉn th·ªã tr√™n Streamlit
        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        frame_window.image(frame)

    cap.release()